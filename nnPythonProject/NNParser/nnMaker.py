# -*- coding: utf-8 -*-
"""RND

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JJfyQj5YH14GBZJmhD3i_UR4rt10d7ze
"""

# Simple Python Script for Converting bias.dat, test.dat and weights.dat
# files to a file structure used in Adaptive Neural Networks

import pandas as pd
import numpy as np
import keras
from keras.datasets import mnist
import keras.utils
from tensorflow import keras
from keras.utils.np_utils import to_categorical

from keras import layers
from sklearn.decomposition import PCA
import keras.initializers
import os

def sigmoid_approx(x):
    return 0.5*(x/(1+abs(x)))+0.5

def to_fixed(f,e,totalBits):
    #return f
    a = f* (2**e)
    b = int(round(a))
    if a < 0:
        # next three lines turns b into it's 2's complement.
        b = 2**totalBits - abs(b)
    return b

def to_float(x,e):
    c = abs(x)
    sign = 1 
    if x < 0:
        # convert back from two's complement
        c = x - 1 
        c = ~c
        sign = -1
    f = (1.0 * c) / (2 ** e)
    f = f * sign
    return f

def TrainNetwork(neurons, act, epo, inputSize):
    # Model / data parameters
    num_classes = 10
    batch_size = 128
    input_shape = inputSize
    epochs = epo

    if len(neurons) != len(act):
      print("Num of neruons and act not the same")
      return

    # the data, split between train and test sets
    (x_train, y_train), (x_test, y_test) = mnist.load_data()

    # Scale images to the [0, 1] range
    x_train = x_train.astype("float32") / 255
    x_test = x_test.astype("float32") / 255

    reshaped_training_data = x_train.ravel().reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])
    reshaped_test_data = x_test.ravel().reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])

    # convert class vectors to binary class matrices
    y_train = to_categorical(y_train, num_classes)
    y_test = to_categorical(y_test, num_classes)

    # Run PCA
    pca = PCA(n_components=input_shape, random_state=42)
    X_pca_train = pca.fit_transform(reshaped_training_data)
    X_pca_test = pca.transform(reshaped_test_data)

    model = keras.Sequential()
    model.add(keras.Input(shape=input_shape))
    for i in range(len(neurons)): 
        model.add(layers.Dense(neurons[i], activation=act[i], kernel_initializer=keras.initializers.random_normal(mean=0.0, stddev=0.05, seed=1),
                         bias_initializer='zeros'))    
        
    model.build()
    model.summary()

    model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
    model.fit(X_pca_train, y_train, batch_size=batch_size, epochs=epochs)

    print(model.layers[0].get_weights())

    for layer in model.layers:
        all = []
        weights_ = []
        bias_ = []
        layer_get_weights = layer.get_weights()[0]
        for neuron in layer_get_weights:
            adder = []
            for weight in neuron:
                adder.append(to_float(to_fixed(weight, 8, 16),8))
            weights_.append(adder)
        
        layer_get_bias = layer.get_weights()[1]
        for neuron in layer_get_bias:
            bias_.append(to_float(to_fixed(neuron,8,16),8))

        print(layer.get_weights()[0].shape)
        print(np.asarray(weights_).shape)
        print(layer.get_weights()[1].shape)
        print(np.asarray(bias_).shape)
        print(np.asarray(layer.get_weights()).shape)
        print(np.asarray([weights_, bias_]).shape)

        layer.set_weights([weights_, bias_])

                

    score = model.evaluate(X_pca_train, y_train, verbose=0)
    predict = model.predict(X_pca_test)

    print("Test loss:", score[0])
    print("Test accuracy:", score[1])

    store_test_images_labels(X_pca_test, y_test)
    store_bias_CSV("bias.csv", model)
    store_weight_CSV("weights.csv", model, True)
    store_bias_CSV("bias_opti.csv", model)
    store_weight_CSV("weights_opti.csv", model, False) # Den skal nok vÃ¦re false anyways!!

def store_bias_CSV(fileName, model):
    if os.path.exists(fileName):
        os.remove(fileName)
    f = open(fileName, "a")
    for layer in model.layers:
        for bias in layer.get_weights()[1]:
            f.write(str(to_fixed(bias,8,16)) + ",")
        f.write("\r\n")
    f.close()

def store_weight_CSV(fileName, model, transpose):
    if os.path.exists(fileName):
        os.remove(fileName)
    f = open(fileName, "a")
    for layer in model.layers:
        layer_get_weights = layer.get_weights()[0]
        if transpose == True:
            layer_get_weights = layer_get_weights.transpose()

        for neuron in layer_get_weights:
            for weight in neuron:
                f.write(str(to_fixed(weight,8,16)) + ",")
        f.write("\r\n")
    f.close()

def store_test_images_labels(testImages, testLabels):
    
    f = open("t.txt", "w")
    for idx,sample in enumerate(testImages):
      for component in sample:
        f.write(str(to_fixed(component,8,16)) + ",")
      f.write("\n")
    
    f = open("l.txt", "w")
    for label in testLabels:
      f.write(str(np.argmax(label)) + ",")
      f.write("\n")
  

def load_dat_files(file_path):
    return pd.read_csv(file_path, header=None).iloc[:, :-1]

def actLoopup(act):
    if(act == "relu"):
      return 1
    elif(act == sigmoid_approx):
      return 2
    elif(act == "softmax"):
      return 3
    else:
      return 0

def createNNConfigFile(filename, bias, weights, act):

    # If File exists Make new
    if os.path.exists(filename):
        os.remove(filename)

    file1 = open(filename, "a")
    # for each layer
    for i in range(bias[0].size):
        layersWeights = weights.iloc[i]
        layersBias = bias.iloc[i]

        layersWeights = layersWeights.dropna().astype(int)
        # Inputing the weights into string
        for j in range(layersWeights.size):
            if not np.isnan(layersWeights[j]):
                if j == layersWeights.size-1:
                    #file1.write(str(float("{:.3f}".format(layersWeights[j]))))
                    file1.write(str(layersWeights[j]))
                else:
                    #file1.write(str(float("{:.3f}".format(layersWeights[j]))) + ",")
                    file1.write(str(layersWeights[j]) + ",")

        # Adding the FA Seperator
        file1.write(",FA," + str(actLoopup(act[i])) + ",FB,")

        # Adding the Biases

        layersBias = layersBias.dropna().astype(int)
        for j in range(layersBias.size):
            if not np.isnan(layersBias[j]):
                if j == layersBias.size-1:
                    #file1.write(str(float("{:.3f}".format(layersBias[j]))))
                    file1.write(str(layersBias[j]))
                else:
                    #file1.write(str(float("{:.3f}".format(layersBias[j]))) + ",")
                    file1.write(str(layersBias[j]) + ",")

        # Add newline
        file1.write("\n")

    file1.close()

if __name__ == '__main__':
    #neurons = [120, 120, 120, 120, 120, 120, 120, 80, 60, 10]
    #act = ["relu", "relu", "relu", "relu", "relu", "relu", "relu", "relu", "relu", "softmax"]
    neurons = [10, 10]
    act = ["relu", "softmax"]

    TrainNetwork(neurons, act, 1, 10)

    bias = load_dat_files('bias.csv')
    weights = load_dat_files('weights.csv')
    createNNConfigFile("bwnorm.txt", bias, weights, act)

    bias = load_dat_files('bias_opti.csv')
    weights = load_dat_files('weights_opti.csv')
    createNNConfigFile("bwopti.txt", bias, weights, act)